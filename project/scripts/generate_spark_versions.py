#!/usr/bin/env python3
"""
Generate Spark version information for CI/CD from CrossSparkVersions.scala

This script reads the JSON file generated by `build/sbt exportSparkVersionsJson`
and provides utilities for GitHub Actions workflows.

Usage:
    # Generate GitHub Actions matrix JSON
    python project/scripts/generate_spark_versions.py --github-matrix
    # Output: ["4.0", "4.1"] or ["master", "4.0"] if master is present

    # Get a specific field for a Spark version (using short version or "master")
    python project/scripts/generate_spark_versions.py --get-field 4.0 targetJvm
    python project/scripts/generate_spark_versions.py --get-field master targetJvm
    # Output: "17"
"""

import argparse
import json
import sys
from pathlib import Path


def load_spark_versions(json_path: Path):
    """Load Spark versions from JSON file."""
    if not json_path.exists():
        print(
            f"ERROR: Spark versions JSON not found at {json_path}\n"
            f"Please run: build/sbt exportSparkVersionsJson",
            file=sys.stderr
        )
        sys.exit(1)

    with open(json_path, 'r') as f:
        return json.load(f)


def main():
    parser = argparse.ArgumentParser(
        description="Generate Spark version information from CrossSparkVersions.scala"
    )
    parser.add_argument(
        "--github-matrix",
        action="store_true",
        help="Output GitHub Actions matrix JSON for spark_version"
    )
    parser.add_argument(
        "--get-field",
        nargs=2,
        metavar=("SPARK_VERSION", "FIELD"),
        help="Get a specific field for a Spark version (e.g., --get-field 4.0 targetJvm or --get-field master targetJvm)"
    )

    args = parser.parse_args()

    # Determine JSON path (relative to repo root)
    script_dir = Path(__file__).parent
    repo_root = script_dir.parent.parent
    json_path = repo_root / "target" / "spark-versions.json"

    try:
        versions = load_spark_versions(json_path)

        if args.github_matrix:
            # For master version, use "master"; for others, use short version
            matrix_versions = []
            for v in versions:
                if v.get("isMaster", False):
                    matrix_versions.append("master")
                else:
                    matrix_versions.append(v["shortVersion"])
            print(json.dumps(matrix_versions))

        elif args.get_field:
            spark_version, field = args.get_field
            
            # Find the version entry by matching:
            # - "master" matches isMaster=true
            # - short version like "4.0" matches shortVersion
            # - full version like "4.0.1" matches fullVersion
            version_entry = None
            for v in versions:
                if spark_version == "master" and v.get("isMaster", False):
                    version_entry = v
                    break
                elif spark_version == v["shortVersion"] or spark_version == v["fullVersion"]:
                    version_entry = v
                    break

            if not version_entry:
                print(f"ERROR: Spark version '{spark_version}' not found", file=sys.stderr)
                sys.exit(1)

            if field not in version_entry:
                print(
                    f"ERROR: Field '{field}' not found for Spark version {spark_version}\n"
                    f"Available fields: {', '.join(version_entry.keys())}",
                    file=sys.stderr
                )
                sys.exit(1)

            # Print as JSON for proper formatting
            print(json.dumps(version_entry[field]))

        else:
            parser.print_help()
            sys.exit(1)

    except Exception as e:
        print(f"ERROR: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
