# âœ… URI ç¼–ç é—®é¢˜ä¿®å¤ - æœ€ç»ˆå®Œæˆ

## ğŸ¯ æµ‹è¯•ç»“æœ
**æ‰€æœ‰ 11 ä¸ª idempotent write æµ‹è¯• 100% é€šè¿‡ï¼**

```
âœ… idempotent write: idempotent DataFrame insert
âœ… idempotent write: idempotent SQL insert  
âœ… idempotent write: idempotent DeltaTable merge
âœ… idempotent write: idempotent SQL merge
âœ… idempotent write: idempotent DeltaTable update
âœ… idempotent write: idempotent SQL update
âœ… idempotent write: idempotent DeltaTable delete
âœ… idempotent write: idempotent SQL delete
âœ… idempotent write: valid txnVersion
âœ… idempotent write: auto reset txnVersion
âœ… idempotent writes in streaming foreachBatch

Run completed in 37 seconds
Total: 11/11 é€šè¿‡ (100%) âœ…
```

## ğŸ“ å®Œæ•´ä¿®æ”¹

### ä¿®æ”¹ 1ï¼šSparkTable.java - è§£ç è¡¨è·¯å¾„

**æ–‡ä»¶**ï¼š`kernel-spark/src/main/java/io/delta/kernel/spark/catalog/SparkTable.java`

```java
public SparkTable(
    Identifier identifier, org.apache.spark.sql.catalyst.catalog.CatalogTable catalogTable) {
  this(
      identifier,
      getDecodedPath(requireNonNull(catalogTable, "catalogTable is null").location()),  // â† ä¿®æ”¹
      Collections.emptyMap(),
      Optional.of(catalogTable));
}

/**
 * Helper method to decode URI path handling URL-encoded characters correctly.
 * E.g., converts "spark%25dir%25prefix" to "spark%dir%prefix"
 */
private static String getDecodedPath(java.net.URI location) {
  try {
    // Use new File(URI).getPath() to get properly decoded filesystem path
    return new java.io.File(location).getPath();
  } catch (IllegalArgumentException e) {
    // Fallback to toString() if URI is not a file:// URI
    return location.toString();
  }
}
```

**æ•ˆæœ**ï¼šDelta Kernel å¯ä»¥æ­£ç¡®æ‰¾åˆ° `_delta_log` ç›®å½•

### ä¿®æ”¹ 2ï¼šSparkScan.java - è§£ç æ•°æ®æ–‡ä»¶è·¯å¾„

**æ–‡ä»¶**ï¼š`kernel-spark/src/main/java/io/delta/kernel/spark/read/SparkScan.java`

```java
// Build file path: decode the relative path from AddFile first (it may be URL-encoded),
// then combine with table path, and finally convert to URI
final String decodedRelativePath =
    java.net.URLDecoder.decode(addFile.getPath(), java.nio.charset.StandardCharsets.UTF_8);  // â† æ–°å¢
final String filePath = java.nio.file.Paths.get(tablePath, decodedRelativePath).toString();  // â† ä¿®æ”¹
final java.net.URI fileUri = new java.io.File(filePath).toURI();  // â† æ–°å¢

final PartitionedFile partitionedFile =
    new PartitionedFile(
        getPartitionRow(addFile.getPartitionValues()),
        SparkPath.fromPath(new org.apache.hadoop.fs.Path(fileUri)),  // â† ä¿®æ”¹
        0L,
        addFile.getSize(),
        locations,
        addFile.getModificationTime(),
        addFile.getSize(),
        otherConstantMetadataColumnValues);
```

**æ•ˆæœ**ï¼šSpark å¯ä»¥æ­£ç¡®è¯»å–åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ•°æ®æ–‡ä»¶

## ğŸ”‘ å…³é”®ä¿®å¤ç‚¹

### 1. è§£ç  CatalogTable è·¯å¾„
- **ä¿®æ”¹å‰**ï¼š`catalogTable.location().toString()` â†’ ä¿ç•™ URL ç¼–ç  `spark%25dir%25prefix`
- **ä¿®æ”¹å**ï¼š`getDecodedPath(catalogTable.location())` â†’ è§£ç ä¸º `spark%dir%prefix`

### 2. è§£ç  AddFile è·¯å¾„  
- **ä¿®æ”¹å‰**ï¼š`addFile.getPath()` â†’ ä¿ç•™ URL ç¼–ç  `test%25file%25prefix`
- **ä¿®æ”¹å**ï¼š`URLDecoder.decode(addFile.getPath())` â†’ è§£ç ä¸º `test%file%prefix`

### 3. æ­£ç¡®çš„è·¯å¾„æ‹¼æ¥
- **ä¿®æ”¹å‰**ï¼šå­—ç¬¦ä¸²æ‹¼æ¥ `tablePath + addFile.getPath()`
- **ä¿®æ”¹å**ï¼š`Paths.get(tablePath, decodedRelativePath)`

### 4. æ­£ç¡®çš„ URI è½¬æ¢
- **ä¿®æ”¹å‰**ï¼š`SparkPath.fromUrlString()` â†’ ä¼šå°è¯•è§£æ URL å­—ç¬¦ä¸²
- **ä¿®æ”¹å**ï¼š`SparkPath.fromPath(new Path(uri))` â†’ ç›´æ¥ä½¿ç”¨ URI

## ğŸ“Š URL ç¼–ç å¤„ç†æµç¨‹

### å®Œæ•´çš„ç¼–ç /è§£ç é“¾

```
1. Hive Metastore/Catalog
   â†“
   URI: file:///tmp/spark%25dir%25prefix  (URL ç¼–ç å­˜å‚¨)
   â†“
2. catalogTable.location()
   â†“
   URI object
   â†“
3. new File(URI).getPath()  â† è§£ç æ­¥éª¤ 1
   â†“
   String: "/tmp/spark%dir%prefix"  (æ–‡ä»¶ç³»ç»Ÿè·¯å¾„)
   â†“
4. Delta Kernel è®¿é—®
   â†“
   âœ… æˆåŠŸæ‰¾åˆ° _delta_log

5. AddFile ä» Delta Log è¯»å–
   â†“
   String: "test%25file%25prefix-part-00000.parquet"  (URL ç¼–ç )
   â†“
6. URLDecoder.decode()  â† è§£ç æ­¥éª¤ 2
   â†“
   String: "test%file%prefix-part-00000.parquet"  (è§£ç )
   â†“
7. Paths.get(tablePath, decodedPath)
   â†“
   String: "/tmp/spark%dir%prefix/test%file%prefix-part-00000.parquet"
   â†“
8. new File(path).toURI()  â† é‡æ–°ç¼–ç 
   â†“
   URI: file:///tmp/spark%25dir%25prefix/test%25file%25prefix-part-00000.parquet
   â†“
9. SparkPath.fromPath(new Path(uri))
   â†“
   âœ… æˆåŠŸè¯»å–æ–‡ä»¶
```

## ğŸ“ æ ¸å¿ƒåŸåˆ™æ€»ç»“

| åœºæ™¯ | ä½¿ç”¨ API | åŸå›  |
|------|---------|------|
| **URI â†’ æ–‡ä»¶ç³»ç»Ÿè·¯å¾„** | `new File(URI).getPath()` | è‡ªåŠ¨è§£ç  URL ç¼–ç  |
| **å­—ç¬¦ä¸² â†’ æ–‡ä»¶ç³»ç»Ÿè·¯å¾„** | `URLDecoder.decode(str)` | æ‰‹åŠ¨è§£ç  URL ç¼–ç  |
| **æ–‡ä»¶ç³»ç»Ÿè·¯å¾„ â†’ URI** | `new File(path).toURI()` | è‡ªåŠ¨ç¼–ç ç‰¹æ®Šå­—ç¬¦ |
| **è·¯å¾„æ‹¼æ¥** | `Paths.get(parent, child)` | è·¨å¹³å°å®‰å…¨æ‹¼æ¥ |
| **Spark Path** | `SparkPath.fromPath(hadoopPath)` | é¿å…äºŒæ¬¡ URI è§£æ |

## âš ï¸ ä¸è¦è¿™æ ·åš

```java
// âŒ é”™è¯¯ï¼šç›´æ¥ toString() ä¿ç•™äº† URL ç¼–ç 
catalogTable.location().toString()

// âŒ é”™è¯¯ï¼šå­—ç¬¦ä¸²æ‹¼æ¥æ— æ³•å¤„ç†ç‰¹æ®Šå­—ç¬¦
tablePath + "/" + addFile.getPath()

// âŒ é”™è¯¯ï¼šfromUrlString ä¼šå°è¯•è§£æå¯¼è‡´é”™è¯¯
SparkPath.fromUrlString(path)

// âŒ é”™è¯¯ï¼šæ··åˆç¼–ç å’Œæœªç¼–ç è·¯å¾„
Paths.get(decodedPath, encodedPath)
```

## âœ… åº”è¯¥è¿™æ ·åš

```java
// âœ… æ­£ç¡®ï¼šè§£ç  URI åˆ°æ–‡ä»¶ç³»ç»Ÿè·¯å¾„
new File(catalogTable.location()).getPath()

// âœ… æ­£ç¡®ï¼šè§£ç  URL ç¼–ç çš„å­—ç¬¦ä¸²
URLDecoder.decode(addFile.getPath(), StandardCharsets.UTF_8)

// âœ… æ­£ç¡®ï¼šå®‰å…¨æ‹¼æ¥æ–‡ä»¶ç³»ç»Ÿè·¯å¾„
Paths.get(tablePath, relativePath).toString()

// âœ… æ­£ç¡®ï¼šæ–‡ä»¶ç³»ç»Ÿè·¯å¾„è½¬ URIï¼ˆè‡ªåŠ¨ç¼–ç ï¼‰
new File(filePath).toURI()

// âœ… æ­£ç¡®ï¼šä½¿ç”¨ fromPath ä¼ é€’ URI
SparkPath.fromPath(new Path(fileUri))
```

## ğŸ“ ä¿®æ”¹çš„æ–‡ä»¶

1. **kernel-spark/src/main/java/io/delta/kernel/spark/catalog/SparkTable.java**
   - â• æ·»åŠ  `getDecodedPath(URI)` é™æ€æ–¹æ³•ï¼ˆ14è¡Œï¼‰
   - âœï¸ ä¿®æ”¹ `CatalogTable` æ„é€ å‡½æ•°è°ƒç”¨ `getDecodedPath()`ï¼ˆ1è¡Œï¼‰

2. **kernel-spark/src/main/java/io/delta/kernel/spark/read/SparkScan.java**
   - âœï¸ ä¿®æ”¹æ–‡ä»¶è·¯å¾„æ‹¼æ¥é€»è¾‘ï¼ˆ6è¡Œï¼‰
   - â• æ·»åŠ  `URLDecoder.decode()` è°ƒç”¨
   - âœï¸ ä¿®æ”¹ä½¿ç”¨ `Paths.get()` æ‹¼æ¥
   - âœï¸ ä¿®æ”¹ä½¿ç”¨ `File.toURI()` ç¼–ç 
   - âœï¸ ä¿®æ”¹ä½¿ç”¨ `SparkPath.fromPath()`

**æ€»è®¡**ï¼š2 ä¸ªæ–‡ä»¶ï¼Œçº¦ 20 è¡Œä»£ç ä¿®æ”¹

## ğŸš€ è¿è¡Œæµ‹è¯•

```bash
# å•ä¸ªæµ‹è¯•
./build/sbt "testOnly org.apache.spark.sql.delta.DeltaSuite -- -z \"idempotent SQL update\""

# æ‰€æœ‰ idempotent write æµ‹è¯•
./build/sbt "testOnly org.apache.spark.sql.delta.DeltaSuite -- -z \"idempotent write\""

# å®Œæ•´ DeltaSuite
./build/sbt "testOnly org.apache.spark.sql.delta.DeltaSuite"
```

## ğŸ‰ ç»“è®º

é€šè¿‡æ­£ç¡®å¤„ç† URL ç¼–ç å’Œæ–‡ä»¶ç³»ç»Ÿè·¯å¾„çš„è½¬æ¢ï¼ŒæˆåŠŸä¿®å¤äº†æ‰€æœ‰ idempotent write æµ‹è¯•ã€‚

**å…³é”®è¦ç‚¹**ï¼š
- å§‹ç»ˆæ˜ç¡®å½“å‰å¤„ç†çš„æ˜¯ URL ç¼–ç è¿˜æ˜¯æ–‡ä»¶ç³»ç»Ÿè·¯å¾„
- ä½¿ç”¨æ­£ç¡®çš„ Java API è¿›è¡Œç¼–ç /è§£ç 
- åœ¨è·¯å¾„æ‹¼æ¥å‰ç»Ÿä¸€è§£ç 
- åœ¨éœ€è¦ URI æ—¶é‡æ–°ç¼–ç 

---

**ä¿®å¤å®Œæˆ**ï¼š2025-10-24  
**æµ‹è¯•é€šè¿‡ç‡**ï¼š11/11 (100%) âœ…  
**ä¿®æ”¹æ–‡ä»¶æ•°**ï¼š2 ä¸ª  
**ä»£ç è¡Œæ•°**ï¼š~20 è¡Œ

