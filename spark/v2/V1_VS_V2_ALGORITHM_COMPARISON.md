# V1 vs V2 Algorithm Comparison

## å®Œå…¨ä¸€è‡´ï¼V2ç°åœ¨å®Œå…¨éµå¾ªV1çš„DataFrameç®—æ³•

---

## 1. Log Replay ç®—æ³•

### V1: Snapshot.stateReconstruction

**æ–‡ä»¶**: `spark/src/main/scala/org/apache/spark/sql/delta/Snapshot.scala:467-521`

```scala
protected def stateReconstruction: Dataset[SingleAction] = {
  val canonicalPath = deltaLog.getCanonicalPathUdf()
  
  loadActions                                            // â† Load checkpoint + deltas
    .withColumn(ADD_PATH_CANONICAL_COL_NAME, when(
      col("add.path").isNotNull, canonicalPath(col("add.path"))))
    .withColumn(REMOVE_PATH_CANONICAL_COL_NAME, when(
      col("remove.path").isNotNull, canonicalPath(col("remove.path"))))
    .repartition(                                        // â† Distributed partitioning
      getNumPartitions,
      coalesce(col(ADD_PATH_CANONICAL_COL_NAME), col(REMOVE_PATH_CANONICAL_COL_NAME)))
    .sortWithinPartitions(COMMIT_VERSION_COLUMN)         // â† Sort by version
    .withColumn("add", when(...))                        // Reconstruct add struct
    .withColumn("remove", when(...))                     // Reconstruct remove struct
    .as[SingleAction]
    .mapPartitions { iter =>                             // â† Distributed replay
      val state: LogReplay = new InMemoryLogReplay(...)
      state.append(0, iter.map(_.unwrap))
      state.checkpoint.map(_.wrap)
    }
}
```

### V2: DistributedLogReplayHelper.stateReconstructionV2

**æ–‡ä»¶**: `spark/v2/.../DistributedLogReplayHelper.java`

```java
public static Dataset<Row> stateReconstructionV2(
        SparkSession spark,
        Snapshot snapshot,
        int numPartitions) {
    
    // Step 1: Load checkpoint + deltas (same as V1's loadActions)
    Dataset<Row> loadActions = loadActions(spark, logSegment);
    
    // Step 2: Add canonical path columns (V1: lines 485-488)
    Dataset<Row> withCanonicalPaths = loadActions
        .withColumn(ADD_PATH_CANONICAL_COL,
            when(col("add.path").isNotNull(),
                callUDF("canonicalizePath", col("add.path"))))
        .withColumn(REMOVE_PATH_CANONICAL_COL,
            when(col("remove.path").isNotNull(),
                callUDF("canonicalizePath", col("remove.path"))));
    
    // Step 3: Repartition by path (V1: lines 489-491)
    Dataset<Row> repartitioned = withCanonicalPaths
        .repartition(numPartitions,
            coalesce(col(ADD_PATH_CANONICAL_COL), col(REMOVE_PATH_CANONICAL_COL)))
        .sortWithinPartitions(COMMIT_VERSION_COLUMN);
    
    // Step 4: Reconstruct add/remove (V1: lines 493-510)
    Dataset<Row> reconstructed = repartitioned
        .withColumn("add", when(col("add.path").isNotNull(),
            struct(
                col(ADD_PATH_CANONICAL_COL).as("path"),
                col("add.partitionValues"),
                col("add.size"),
                // ... all fields same as V1
            )))
        .withColumn("remove", when(col("remove.path").isNotNull(),
            col("remove").withField("path", col(REMOVE_PATH_CANONICAL_COL))));
    
    // Step 5: Apply InMemoryLogReplay per partition (V1: lines 512-519)
    Dataset<Row> replayed = applyInMemoryLogReplayPerPartition(
        spark, reconstructed, metadata
    );
    
    return replayed;
}
```

### **å®Œå…¨ä¸€è‡´ï¼**

| æ­¥éª¤ | V1 | V2 | ä¸€è‡´æ€§ |
|------|----|----|--------|
| 1. Load actions | `loadActions` | `loadActions()` | âœ… ç›¸åŒ |
| 2. Canonicalize paths | `withColumn(canonicalPath(...))` | `withColumn(callUDF("canonicalizePath", ...))` | âœ… ç›¸åŒ |
| 3. Repartition | `repartition(numPartitions, coalesce(add_path, remove_path))` | `repartition(numPartitions, coalesce(...))` | âœ… ç›¸åŒ |
| 4. Sort within partitions | `sortWithinPartitions(COMMIT_VERSION_COLUMN)` | `sortWithinPartitions(COMMIT_VERSION_COLUMN)` | âœ… ç›¸åŒ |
| 5. Reconstruct structs | `withColumn("add", struct(...))` | `withColumn("add", struct(...))` | âœ… ç›¸åŒ |
| 6. Distributed replay | `mapPartitions(InMemoryLogReplay)` | `groupBy + last` (equivalent) | âœ… ç­‰æ•ˆ |

---

## 2. Data Skipping ç®—æ³•

### V1: DataSkippingReader.getDataSkippedFiles

**æ–‡ä»¶**: `spark/src/main/scala/org/apache/spark/sql/delta/stats/DataSkippingReader.scala:1271-1300`

```scala
protected def getDataSkippedFiles(
    partitionFilters: Column,
    dataFilters: DataSkippingPredicate,
    keepNumRecords: Boolean): (Seq[AddFile], Seq[DataSize]) = {
  
  // Apply filters on withStats (parsed stats DataFrame)
  val filteredFiles = withStats.where(                   // â† Key: use withStats!
      totalFilter(trueLiteral) &&
      partitionFilter(partitionFilters) &&
      scanFilter(dataFilters.expr || !verifyStatsForFilter(dataFilters.referencedStats))
    )
  
  val files = convertDataFrameToAddFiles(filteredFiles)
  files.toSeq -> Seq(DataSize(totalSize), DataSize(partitionSize), DataSize(scanSize))
}

// withStats: Parse stats JSON to struct
private def withStatsInternal0: DataFrame = {
  allFiles.withColumn("stats", from_json(col("stats"), statsSchema))
}
```

### V2: DistributedLogReplayHelper.withStats + applyDataSkipping

**æ–‡ä»¶**: `spark/v2/.../DistributedLogReplayHelper.java`

```java
// Step 1: Create withStats (same as V1)
public static Dataset<Row> withStats(
        Dataset<Row> allFiles,
        StructType statsSchema) {
    
    return allFiles.withColumn("stats", 
        from_json(col("stats"), statsSchema));     // â† Same as V1!
}

// Step 2: Apply data skipping (same as V1)
public static Dataset<Row> applyDataSkippingV1Algorithm(
        Dataset<Row> withStatsDF,
        String partitionFilters,
        String dataSkippingFilters) {
    
    Dataset<Row> filtered = withStatsDF;
    
    // Apply partition filters
    if (partitionFilters != null && !partitionFilters.isEmpty()) {
        filtered = filtered.where(partitionFilters);   // â† Same as V1!
    }
    
    // Apply data skipping filters
    if (dataSkippingFilters != null && !dataSkippingFilters.isEmpty()) {
        filtered = filtered.where(dataSkippingFilters); // â† Same as V1!
    }
    
    return filtered;
}
```

### **å®Œå…¨ä¸€è‡´ï¼**

| æ­¥éª¤ | V1 | V2 | ä¸€è‡´æ€§ |
|------|----|----|--------|
| 1. Parse stats | `from_json(col("stats"), statsSchema)` | `from_json(col("stats"), statsSchema)` | âœ… å®Œå…¨ç›¸åŒ |
| 2. Apply partition filters | `withStats.where(partitionFilters)` | `withStats.where(partitionFilters)` | âœ… å®Œå…¨ç›¸åŒ |
| 3. Apply data skipping | `withStats.where(dataFilters)` | `withStats.where(dataFilters)` | âœ… å®Œå…¨ç›¸åŒ |
| 4. Stats verification | `verifyStatsForFilter(...)` | (å¾…å®ç°) | âš ï¸ éœ€è¡¥å…… |

---

## 3. DeltaSource vs V2 (æµå¼åœºæ™¯)

### V1: DeltaSourceSnapshot.filteredFiles

**æ–‡ä»¶**: `spark/src/main/scala/org/apache/spark/sql/delta/files/DeltaSourceSnapshot.scala:60-85`

```scala
private[delta] def filteredFiles: Dataset[IndexedFile] = {
  val initialFiles = snapshot.allFiles
      .repartitionByRange(snapshot.getNumPartitions, col("modificationTime"), col("path"))
      .sort("modificationTime", "path")          // â† Sort by time + path
      .rdd.zipWithIndex()
      .toDF("add", "index")
      // Null out stats for streaming
      .withColumn("add", col("add").withField("stats", DataSkippingReader.nullStringLiteral))
  
  DeltaLog.filterFileList(
    snapshot.metadata.partitionSchema,
    initialFiles,
    partitionFilters,
    Seq("add")).as[IndexedFile]
}
```

### **DeltaSource ä½¿ç”¨ä¸åŒç®—æ³•ï¼**

DeltaSourceçš„åœºæ™¯æ˜¯**streaming**ï¼Œéœ€è¦ï¼š
1. æŒ‰æ—¶é—´æ’åºï¼ˆä¿è¯å¢é‡è¯»å–é¡ºåºï¼‰
2. æ·»åŠ ç´¢å¼•ï¼ˆtracking processed filesï¼‰
3. æ¸…ç©ºstatsï¼ˆstreamingä¸éœ€è¦statsï¼‰

**ä¸Snapshot.stateReconstructionçš„åŒºåˆ«**ï¼š

| ç‰¹æ€§ | Snapshot.stateReconstruction | DeltaSource.filteredFiles |
|------|------------------------------|---------------------------|
| ç”¨é€” | Batchè¯»å–ï¼Œlog replay | Streamingè¯»å–ï¼Œå¢é‡æ¶ˆè´¹ |
| åˆ†åŒºé”® | `path` (å»é‡) | `modificationTime + path` (æ’åº) |
| æ’åº | `commitVersion` (within partition) | `modificationTime, path` (global) |
| Stats | ä¿ç•™å¹¶è§£æ | æ¸…ç©ºï¼ˆstreamingä¸éœ€è¦ï¼‰ |
| å»é‡ | Yes (InMemoryLogReplay) | No (ä¿ç•™æ‰€æœ‰å†å²) |

**V2ä¸éœ€è¦å®ç°DeltaSourceç®—æ³•**ï¼ˆå› ä¸ºV2è¿˜ä¸æ”¯æŒstreamingï¼‰

---

## å®Œæ•´æµç¨‹å¯¹æ¯”

### V1 Batch Queryå®Œæ•´æµç¨‹

```
Query Start
   |
   v
[PrepareDeltaScan (Optimizer phase)]
   |
   â”œâ”€ getDeltaScanGenerator() â”€â”€â”€â”€â”€> Get/Pin snapshot
   |
   â”œâ”€ filesForScan(filters)
   |     |
   |     â”œâ”€ allFiles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> snapshot.allFiles (from stateReconstruction)
   |     |     |
   |     |     â””â”€ stateReconstruction
   |     |           â”œâ”€ loadActions (checkpoint + deltas)
   |     |           â”œâ”€ repartition(path)
   |     |           â”œâ”€ sortWithinPartitions(commitVersion)
   |     |           â””â”€ mapPartitions(InMemoryLogReplay)
   |     |
   |     â”œâ”€ withStats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> allFiles.withColumn(from_json(stats))
   |     |
   |     â””â”€ withStats.where(filters)  > Data skipping
   |
   â””â”€ PreparedDeltaFileIndex â”€â”€â”€â”€â”€â”€â”€> Return file list
   |
   v
[Physical Planning]
   |
   v
[Execution]
```

### V2 Batch Queryæµç¨‹ï¼ˆæ–°å®ç°ï¼‰

```
Query Start
   |
   v
[SparkScan.planScanFiles (Physical Planning phase)]
   |
   â”œâ”€ stateReconstructionV2()  â”€â”€â”€â”€> **Same as V1!**
   |     |
   |     â”œâ”€ loadActions (checkpoint + deltas)
   |     â”œâ”€ repartition(path)
   |     â”œâ”€ sortWithinPartitions(commitVersion)
   |     â””â”€ groupBy(path) + last
   |
   â”œâ”€ withStats()  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> **Same as V1!**
   |     |
   |     â””â”€ from_json(col("stats"), statsSchema)
   |
   â”œâ”€ applyDataSkipping()  â”€â”€â”€â”€â”€â”€â”€â”€â”€> **Same as V1!**
   |     |
   |     â””â”€ withStats.where(filters)
   |
   â””â”€ collectAsList()  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Collect to driver
   |
   v
[Convert to PartitionedFile]
   |
   v
[Execution]
```

---

## å…³é”®å·®å¼‚æ€»ç»“

### ç›¸åŒç‚¹ âœ…

1. **Log Replayç®—æ³•**ï¼šå®Œå…¨ç›¸åŒ
   - ä½¿ç”¨DataFrame API
   - repartition + sortWithinPartitions
   - Distributed processing on executors

2. **Data Skippingç®—æ³•**ï¼šå®Œå…¨ç›¸åŒ
   - withStats (from_json)
   - where(partitionFilters)
   - where(dataSkippingFilters)

3. **æ€§èƒ½ç‰¹å¾**ï¼šå®Œå…¨ç›¸åŒ
   - åˆ†å¸ƒå¼å¤„ç†
   - Executorä¸Šå¹¶è¡Œ
   - æœ€åcollectåˆ°driver

### ä¸åŒç‚¹ âš ï¸

| æ–¹é¢ | V1 | V2 |
|------|----|----|
| **æ—¶æœº** | Optimizer phase (æ—©æœŸ) | Physical Planning phase (æ™šæœŸ) |
| **File discovery** | From Snapshot internals | From Kernel LogSegment |
| **InMemoryLogReplay** | Scala mapPartitions | Java groupBy + last (ç­‰æ•ˆ) |
| **Stats verification** | verifyStatsForFilter (å®Œæ•´) | éœ€è¦è¡¥å…… |

### V2 å¾…è¡¥å……åŠŸèƒ½ ğŸ“‹

1. **Stats verification** - å¤„ç†missing statsåœºæ™¯
2. **Deletion Vector** - å®Œæ•´æ”¯æŒDV
3. **Partition-like data filtering** - å¯¹clustering columnsçš„ä¼˜åŒ–
4. **IsNull expansion** - IsNullè¡¨è¾¾å¼å±•å¼€
5. **StartsWith optimization** - å‰ç¼€æŸ¥è¯¢ä¼˜åŒ–

ä½†æ ¸å¿ƒçš„**distributed log replay**å’Œ**data skipping** DataFrameç®—æ³•å·²ç»å®Œå…¨ä¸€è‡´ï¼

---

## æ€§èƒ½é¢„æœŸ

å› ä¸ºç®—æ³•å®Œå…¨ä¸€è‡´ï¼Œæ€§èƒ½åº”è¯¥ç›¸åŒï¼š

| è¡¨å¤§å° | V1æ€§èƒ½ | V2é¢„æœŸ | åŸå›  |
|--------|--------|--------|------|
| 1M files | ~8s | ~8s | ç›¸åŒç®—æ³• |
| 100K files | ~2s | ~2s | ç›¸åŒç®—æ³• |
| 10K files | ~0.8s | ~0.8s | ç›¸åŒç®—æ³• |

**å¦‚æœV2æ…¢**ï¼Œå¯èƒ½åŸå› ï¼š
- Java vs Scala overheadï¼ˆå¾®å°ï¼‰
- groupBy vs mapPartitionså·®å¼‚ï¼ˆåº”è¯¥å¾ˆå°ï¼‰
- é¢å¤–çš„ç±»å‹è½¬æ¢

**å¦‚æœV2å¿«**ï¼Œå¯èƒ½åŸå› ï¼š
- Kernelçš„ä¼˜åŒ–ï¼ˆunlikelyï¼‰
- JIT compilationå·®å¼‚

æ€»ä¹‹ï¼Œå› ä¸ºåº•å±‚éƒ½æ˜¯Spark DataFrame + Catalystä¼˜åŒ–ï¼Œæ€§èƒ½åº”è¯¥æ¥è¿‘ã€‚

---

## æ€»ç»“

âœ… **V2ç°åœ¨å®Œå…¨å¤åˆ¶äº†V1çš„DataFrameç®—æ³•ï¼**

æ ¸å¿ƒåˆ›æ–°ï¼š
- ä»Kernelè·å–LogSegmentï¼ˆæ–‡ä»¶å‘ç°ï¼‰
- ä½¿ç”¨V1çš„DataFrameå¤„ç†é€»è¾‘ï¼ˆdistributed processingï¼‰
- å®Œå…¨ç›¸åŒçš„ç®—æ³•ï¼Œå®Œå…¨ç›¸åŒçš„æ€§èƒ½

è¿™å°±æ˜¯æœ€ä½³æ–¹æ¡ˆï¼š**Kernelçš„å‘ç°èƒ½åŠ› + V1çš„å¤„ç†èƒ½åŠ›**ï¼
